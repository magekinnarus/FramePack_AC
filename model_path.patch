--- a/demo_gradio.py
+++ b/demo_gradio.py
@@ -1,11 +1,11 @@
-from diffusers_helper.hf_login import login
-
 import os
 
-os.environ['HF_HOME'] = os.path.abspath(os.path.realpath(os.path.join(os.path.dirname(__file__), './hf_download')))
+# Define the root directory for all your downloaded models
+# This path must match the DOWNLOAD_ROOT used in your Colab download script.
+DOWNLOAD_ROOT = '/content/downloaded_models'
 
 import gradio as gr
 import torch
 import traceback
 import einops
 import safetensors.torch as sf
@@ -49,19 +49,19 @@
 print(f'Free VRAM {free_mem_gb} GB')
 print(f'High-VRAM Mode: {high_vram}')
 
-text_encoder = LlamaModel.from_pretrained("hunyuanvideo-community/HunyuanVideo", subfolder='text_encoder', torch_dtype=torch.float16).cpu()
-text_encoder_2 = CLIPTextModel.from_pretrained("hunyuanvideo-community/HunyuanVideo", subfolder='text_encoder_2', torch_dtype=torch.float16).cpu()
-tokenizer = LlamaTokenizerFast.from_pretrained("hunyuanvideo-community/HunyuanVideo", subfolder='tokenizer')
-tokenizer_2 = CLIPTokenizer.from_pretrained("hunyuanvideo-community/HunyuanVideo", subfolder='tokenizer_2')
-vae = AutoencoderKLHunyuanVideo.from_pretrained("hunyuanvideo-community/HunyuanVideo", subfolder='vae', torch_dtype=torch.float16).cpu()
-
-feature_extractor = SiglipImageProcessor.from_pretrained("lllyasviel/flux_redux_bfl", subfolder='feature_extractor')
-image_encoder = SiglipVisionModel.from_pretrained("lllyasviel/flux_redux_bfl", subfolder='image_encoder', torch_dtype=torch.float16).cpu()
-
-transformer = HunyuanVideoTransformer3DModelPacked.from_pretrained('lllyasviel/FramePackI2V_HY', torch_dtype=torch.bfloat16).cpu()
+# Load models from local paths
+text_encoder = LlamaModel.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'hunyuanvideo_text_encoder'), torch_dtype=torch.float16).cpu()
+text_encoder_2 = CLIPTextModel.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'hunyuanvideo_text_encoder_2'), torch_dtype=torch.float16).cpu()
+tokenizer = LlamaTokenizerFast.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'hunyuanvideo_tokenizer'))
+tokenizer_2 = CLIPTokenizer.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'hunyuanvideo_tokenizer_2'))
+vae = AutoencoderKLHunyuanVideo.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'hunyuanvideo_vae'), torch_dtype=torch.float16).cpu()
+
+feature_extractor = SiglipImageProcessor.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'flux_feature_extractor'))
+image_encoder = SiglipVisionModel.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'flux_image_encoder'), torch_dtype=torch.float16).cpu()
+
+transformer = HunyuanVideoTransformer3DModelPacked.from_pretrained(os.path.join(DOWNLOAD_ROOT, 'framepack_transformer'), torch_dtype=torch.bfloat16).cpu()
 
 vae.eval()
 text_encoder.eval()
 text_encoder_2.eval()
 image_encoder.eval()
 transformer.eval()